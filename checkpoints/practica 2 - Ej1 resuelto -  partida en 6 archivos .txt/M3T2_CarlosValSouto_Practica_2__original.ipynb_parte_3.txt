s=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)\n",
            "      )\n",
            "      (2): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)\n",
            "      )\n",
            "      (3): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)\n",
            "      )\n",
            "      (4): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
            "      )\n",
            "      (1): MBConv(\n",
            "        (block): Sequential(\n",
            "          (0): Conv2dNormActivation(\n",
            "            (0): Conv2d(320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            (0): Conv2d(1920, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1920, bias=False)\n",
            "            (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): SiLU(inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "            (fc1): Conv2d(1920, 80, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(80, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): SiLU(inplace=True)\n",
            "            (scale_activation): Sigmoid()\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            (0): Conv2d(1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)\n",
            "      )\n",
            "    )\n",
            "    (8): Conv2dNormActivation(\n",
            "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): SiLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.2, inplace=True)\n",
            "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "============================================================\n",
            "Número total de parámetros: 7,794,184\n"
          ]
        }
      ],
      "source": [
        "# Mostrar la arquitectura del modelo cargado\n",
        "print(\"Arquitectura completa del modelo EfficientNet B1:\")\n",
        "print(model)\n",
        "print(\"\\n\" + \"===\"*20)\n",
        "print(f\"Número total de parámetros: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e050b17",
      "metadata": {},
      "source": [
        "### Comentario de la casilla anterior\n",
        "\n",
        "En la casilla anterior se lista la arquitectura del algoritmo EfficientNet B1, el cual tiene tres secciones principales:\n",
        "1. (features)   =   es el extractor de características. Son todas las capas convolucionales que extraen patrones como bordes, formas, texturas, objetos...\n",
        "2. (avgpool)    =   el Pooling promedio. Ayduda a reducir el tamaño. Convierte los mapas de características a vector.\n",
        "3. (classifier) =   Se trata del clasificador y es la parte final del proceso que usa una red clasica o Red Densa (Fully Connected Network). Contiene 2 capas: Dropout + Linear. REduce las clases a las 4 clases finales y toma la decisión de a que clase pertenecen los datos que le van llegando (las 4 emociones)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "567ac166",
      "metadata": {
        "id": "567ac166"
      },
      "source": [
        "Congela los parámetros de toda la red, es decir, configura los parámetros para que no requieran el cómputo del gradiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "28b5d4c0",
      "metadata": {
        "id": "28b5d4c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parámetros totales: 7,794,184\n",
            "Parámetros congelados: 6,513,184\n",
            "Parámetros entrenables: 1,281,000\n"
          ]
        }
      ],
      "source": [
        "# Congelar todos los parámetros del extractor de características. Itera sobre todos los parámetros de la sección \"features\" con model.features.parameters()\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Verificar cuántos parámetros están congelados vs entrenables\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "frozen_params = total_params - trainable_params\n",
        "\n",
        "print(f\"Parámetros totales: {total_params:,}\")\n",
        "print(f\"Parámetros congelados: {frozen_params:,}\")\n",
        "print(f\"Parámetros entrenables: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b605b988",
      "metadata": {},
      "source": [
        "### Comentario de la casilla anterior\n",
        "\n",
        "El bucle for itera por cada uno de los parámetros de la sección features del model y los congela con \"param.requires_grad = False\".\n",
        "\n",
        "El siguiente bloque verifica cuantos elementos hay en el modelo con la funciond de Pytorch .numel() y los divide en totales y los que estan congelados. Por último, la resta de estos dos valores nos da el total de parametros entrenables, que en realidad es el paso donde el clasifier reduce la clasificación a 1000 clases, que hace lo siguiente: 1000 + bias nos da = 1.281.000 parametros entrenables (si lo he entendido bien)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "954bf69e",
      "metadata": {
        "id": "954bf69e"
      },
      "source": [
        "Localiza la capas o capas que actúan como clasificadores. ¿Cuántas son? ¿Cómo se llama el bloque que las contiene?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "zxC__u5E0mon",
      "metadata": {
        "id": "zxC__u5E0mon"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " BLOQUES PRINCIPALES \n",
            "¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨\n",
            "  1. features\n",
            "  2. avgpool\n",
            "  3. classifier\n",
            "¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨\n",
            " Capas dentro del bloque 'classifier':\n",
            "  1. Dropout\n",
            "  2. Linear\n",
            "¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨\n",
            " El bloque clasificador se llama: classifier\n",
            " Contiene 2 capas: Dropout, Linear\n",
            "¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨\n"
          ]
        }
      ],
      "source": [
        "# mostrar los bloques principales del modelo\n",
        "print(\" BLOQUES PRINCIPALES \")\n",
        "print(\"¨\" * 60)\n",
        "bloques = list(model.named_children())\n",
        "for i, (name, _) in enumerate(bloques):\n",
        "    print(f\"  {i+1}. {name}\")\n",
        "\n",
        "print(\"¨\" * 60)\n",
        "# Obtener  los nombres de las capas dentro del clasificador\n",
        "print(f\" Capas dentro del bloque 'classifier':\")\n",
        "capas_clasificador = [type(capa).__name__ for capa in model.classifier]\n",
        "for i, capa in enumerate(capas_clasificador):\n",
        "    print(f\"  {i+1}. {capa}\")\n",
        "    \n",
        "# print(f\"Capas dentro del bloque 'classifier': {capas_clasificador}\")\n",
        "\n",
        "print(\"¨\" * 60)\n",
        "print(f\" El bloque clasificador se llama: {bloques[2][0]}\")\n",
        "print(f\" Contiene {len(model.classifier)} capas: {', '.join(capas_clasificador)}\")\n",
        "print(\"¨\" * 60)\n",
        "\n",
        "\n",
        "# print(f\"• Contiene {len(model.classifier)} capas: {', '.join(capas_clasificador)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de5a1241",
      "metadata": {},
      "source": [
        "## Comentario de la casilla anterior\n",
        "\n",
        "### En el código anterior hay 3 partes:\n",
        "\n",
        "La primera lista los bloques principales que contiene el modelo. \n",
        "\n",
        "La segunda muestra las capas dentro del modelo clasificador. \n",
        "\n",
        "La tercera es simplemente una respuesta resumida de lo anterior.\n",
        "\n",
        "\n",
        ".\n",
        "\n",
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64ce4722",
      "metadata": {
        "id": "64ce4722"
      },
      "source": [
        "Define un nuevo clasificador adaptado a nuestro problema:\n",
        "*   Una capa de Dropout con probabilidad de **0.3** y que realice la operación **inplace**.\n",
        "*   Una capa Linear adecuada: hay que definir el número de *features* de entrada y el número de *features* de salida.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f7085fe0",
      "metadata": {
        "id": "f7085fe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Modelo completo transferido a: cuda\n",
            "✅ Clasificador en: cuda:0\n"
          ]
        }
      ],
      "source": [
        "in_features = model.classifier[1].in_features\n",
        "num_classes = len(train_dataset.classes)\n",
        "\n",
        "new_head = nn.Sequential(\n",
        "    nn.Dropout(p=0.3, inplace=True),\n",
        "    nn.Linear(in_features, num_classes)\n",
        ")\n",
        "\n",
        "# Transferir el nuevo clasificador a CUDA ANTES de asignarlo\n",
        "new_head = new_head.to(device)\n",
        "model.classifier = new_head\n",
        "\n",
        "model = model.to(device)\n",
        "print(f\"✅ Modelo completo transferido a: {device}\")\n",
        "print(f\"✅ Clasificador en: {next(model.classifier.parameters()).device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea0400ed",
      "metadata": {
        "id": "ea0400ed"
      },
      "source": [
        "Actualiza el clasificador del modelo. Por defecto, el nuevo clasificador no tendrá los pesos congelados y, por tanto, se entrenará."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e32792ea",
      "metadata": {
        "id": "e32792ea"
      },
      "outputs": [],
      "source": [
        "# Actualizar el clasificador del modelo\n",
        "model.classifier = new_head\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d653108c",
      "metadata": {
        "id": "d653108c"
      },
      "source": [
        "Muestra y verifica que el modelo está actualizado con la nueva arquitectura:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4ecd538a",
      "metadata": {
        "id": "4ecd538a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "   CLASIFICADOR ACTUALIZADO \n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "Nuevo clasificador:\n",
            "Sequential(\n",
            "  (0): Dropout(p=0.3, inplace=True)\n",
            "  (1): Linear(in_features=1280, out_features=4, bias=True)\n",
            ")\n",
            "¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨¨\n",
            "\n",
            "Dimensiones